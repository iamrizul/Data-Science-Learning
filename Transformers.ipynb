{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twRn5bllF10b"
   },
   "source": [
    "Real Life Datasets have many features with a wide range of values like for example let’s consider the house price prediction dataset. It will have many features like no. of. bedrooms, square feet area of the house, etc.​\n",
    "\n",
    "As you can guess, the no. of bedrooms will vary between 1 and 5, but the square feet area will range from 500-2000. This is a huge difference in the range of both features.​\n",
    "\n",
    "Many machine learning algorithms that are using Euclidean distance as a metric to calculate the similarities will fail to give a reasonable recognition to the smaller feature, in this case, the number of bedrooms, which in the real case can turn out to be an actually important metric.​\n",
    "\n",
    "Eg: Linear Regression, Logistic Regression, KNN​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7jONJQAGjiUe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier,GradientBoostingClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute._base import SimpleImputer as Imputer\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    " \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "kT8U_OfDjiUi",
    "outputId": "4bc90142-a1b9-4665-bdbc-58af9e8932dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading titanic data and droping PassengerId as it is unique identifier\n",
    "\n",
    "titanic_df = pd.read_csv('train.csv')\n",
    "titanic_df = titanic_df.drop('PassengerId', axis=1)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rblcvyVfjiUj",
    "outputId": "ded37834-bf19-44bc-8688-495ccb7d206a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uFX7EFUujiUj"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "X = titanic_df.drop('Survived', axis=1)\n",
    "y = titanic_df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gl8NvuKAjiUj"
   },
   "outputs": [],
   "source": [
    "# the columns with int or float datatype are considered as numeric features.\n",
    "\n",
    "numeric_features = ['Age', 'Fare']\n",
    "\n",
    "\n",
    "# Qualitative columns\n",
    "categorical_features = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n",
    "\n",
    "\n",
    "name_feature = ['Name']\n",
    "cabin_feature = ['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "mlOWlpOejiUk"
   },
   "outputs": [],
   "source": [
    "# creating a pipeline for numeric columns\n",
    "# we are doing median imputation for null values and then standard scaler\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "# creating pipeline for categorical columns\n",
    "# filling with 'missing' for null values and then one hot encoding the categories\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only first charecter as cabin information, replacing missing values with 'U'! ​  \n",
    "creating dummy variables for encoding categorical column !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MIqRBJnqjiUl"
   },
   "outputs": [],
   "source": [
    "# creating custom transformer for cabin coolumn\n",
    "\n",
    "class CabinFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('in the CabinFeatureTransformer init method: ')\n",
    "            \n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        x.Cabin.fillna('U', inplace=True)\n",
    "        x['Cabin'] = x['Cabin'].map(lambda c: c[0])\n",
    "        \n",
    "        cabin_dummies = pd.get_dummies(x['Cabin'], prefix='Cabin')    \n",
    "        self.cabin_columns=  cabin_dummies.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        # replacing missing cabins with U (for Uknown)\n",
    "        x.Cabin.fillna('U', inplace=True)\n",
    "    \n",
    "        # mapping each Cabin value with the cabin letter\n",
    "        x['Cabin'] = x['Cabin'].map(lambda c: c[0])\n",
    "        \n",
    "        cabin_dummies = pd.get_dummies(x['Cabin'], prefix='Cabin') \n",
    "        cabin_dummies = cabin_dummies.reindex(columns = self.cabin_columns, fill_value=0)\n",
    "        \n",
    "        x = pd.concat([x, cabin_dummies], axis=1)\n",
    "\n",
    "        x.drop('Cabin', axis=1, inplace=True)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating custom transformer for Name columns ​  \n",
    "We are basically trying to extract the Title from name for ex: Officer, Major, etc...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ML-miGPgjiUm"
   },
   "outputs": [],
   "source": [
    "class NameFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        print('in the NameFeatureTransformer Init method: ')\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        Title_Dictionary = {\n",
    "                \"Capt\": \"Officer\", \"Col\": \"Officer\", \"Major\": \"Officer\",\"Jonkheer\": \"Royalty\",\n",
    "                \"Don\": \"Royalty\",\"Sir\" : \"Royalty\",\"Dr\": \"Officer\",\"Rev\": \"Officer\",\"the Countess\":\"Royalty\",\n",
    "                \"Mme\": \"Mrs\", \"Mlle\": \"Miss\", \"Ms\": \"Mrs\", \"Mr\" : \"Mr\", \"Mrs\" : \"Mrs\", \"Miss\" : \"Miss\",\n",
    "                \"Master\" : \"Master\", \"Lady\" : \"Royalty\"}\n",
    "        \n",
    "        x['Title'] = x['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "        x['Title'] = x.Title.map(Title_Dictionary)\n",
    "        \n",
    "        x.drop('Name', axis=1, inplace=True)\n",
    "    \n",
    "        titles_dummies = pd.get_dummies(x['Title'], prefix='Title')\n",
    "        x = pd.concat([x, titles_dummies], axis=1)\n",
    "    \n",
    "        x.drop('Title', axis=1, inplace=True)\n",
    "        return x.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common transformer, that merges all other transformer created and mapped with respected column !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TnfQj5HDjiUn",
    "outputId": "70418d51-4a98-4ec1-c9a2-9ba7f2b6f327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the CabinFeatureTransformer init method: \n",
      "in the NameFeatureTransformer Init method: \n"
     ]
    }
   ],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_data_preprocessing', numeric_transformer, numeric_features),\n",
    "        ('categorical_data_preprocessing', categorical_transformer, categorical_features),\n",
    "        ('cabin_data_preprocessing', CabinFeatureTransformer(), cabin_feature),\n",
    "        ('name_data_preprocessing', NameFeatureTransformer(), name_feature)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the CabinFeatureTransformer init method: \n",
      "in the NameFeatureTransformer Init method: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.79693172, -0.47182993,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.87433616,  0.38903233,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.1002918 ,  0.69775126,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.87433616, -0.45642589,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.36413482,  1.08153862,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.26135834,  0.1373185 ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming the train data using created transformer\n",
    "\n",
    "transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing trained transformer object for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transformer.pkl', 'wb') as f:\n",
    "    pickle.dump(transformer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading back the serialized object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transformer.pkl', 'rb') as f:\n",
    "    saved_transformer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the test data from serialized object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40990954,  0.43297927,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.05451708,  1.51834306,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.87433616, -0.4166246 ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.26135834, -0.46010048,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.44153926, -0.6075011 ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.79693172, -0.47519299,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Titanic_Model_With_Pipeline_CustomTransformer.ipynb.txt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
